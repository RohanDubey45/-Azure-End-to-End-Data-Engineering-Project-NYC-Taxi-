# ğŸš€ Azure Databricks â€“ End-to-End Data Engineering Project (NYC Taxi Data)

<p>
<img src="https://img.shields.io/badge/Microsoft%20Azure-0078D4?style=for-the-badge&logo=microsoftazure&logoColor=white" height="35"/>
<img src="https://img.shields.io/badge/Azure%20Data%20Factory-FF9900?style=for-the-badge" height="35"/>
<img src="https://img.shields.io/badge/Databricks-FF3621?style=for-the-badge&logo=databricks&logoColor=white" height="35"/>
<img src="https://img.shields.io/badge/Delta%20Lake-00B3A4?style=for-the-badge" height="35"/>
<img src="https://img.shields.io/badge/Apache%20Spark-E25A1C?style=for-the-badge&logo=apachespark&logoColor=white" height="35"/>
<img src="https://img.shields.io/badge/Python-3776AB?style=for-the-badge&logo=python&logoColor=white" height="35"/>
</p>

---

## ğŸ“Œ Project Overview

This project demonstrates a **complete Azure Data Engineering pipeline** using:

- Azure Data Factory  
- Azure Databricks  
- PySpark  
- Delta Lake  
- Azure Data Lake Storage Gen2  

The pipeline processes **NYC Taxi data** using the **Bronzeâ€“Silverâ€“Gold (Medallion) architecture** and implements real-world best practices such as dynamic ingestion, secure authentication, and incremental data processing.

---

## ğŸ— Architecture â€“ Medallion Design

### ğŸ¥‰ Bronze Layer (Raw Zone)
- Data dynamically pulled from an API using **Azure Data Factory**
- Parameterized pipelines ingest monthly data automatically
- Stored in **Parquet format**
- Saved in Azure Data Lake Gen2
- No transformations applied

---

### ğŸ¥ˆ Silver Layer (Processed Zone)
- Data read from Bronze using **Azure Databricks**
- Transformations applied using **PySpark**
- Data cleaning and enrichment performed
- Written back to Data Lake in refined format

---

### ğŸ¥‡ Gold Layer (Curated Zone)
- Curated datasets stored in **Delta format**
- Enables:
  - ACID transactions
  - Table versioning
  - Time travel
- Optimized for analytics and querying

---

## ğŸ”„ Project Phases

### Phase 1 â€“ Data Ingestion (Azure Data Factory)

- Created **dynamic pipelines** using parameters and loops
- Ingested NYC Taxi data directly from API
- Eliminated manual uploads
- Stored raw data in Bronze layer (Parquet format)
- Implemented secure authentication using:
  - Azure AD Service Principal
  - Linked Services

---

### Phase 2 â€“ Data Transformation (Azure Databricks + PySpark)

- Accessed Azure Data Lake securely from Databricks
- Applied PySpark transformations:
  - Column selection
  - Data cleaning
  - Enrichment logic
- Pushed refined data to Silver layer

---

### Phase 3 â€“ Delta Lake Implementation

- Converted processed data to **Delta tables**
- Explored:
  - Delta Log
  - Data versioning
  - Time travel capabilities
- Stored curated data in Gold layer

---

## âš™ Key Features

âœ… Medallion architecture (Bronze / Silver / Gold)  
âœ… Dynamic ADF pipeline using parameters  
âœ… Secure Service Principal authentication  
âœ… Parquet storage in ADLS Gen2  
âœ… PySpark transformations in Databricks  
âœ… Delta Lake ACID compliance  
âœ… Incremental and automated data processing  

---

## ğŸ§° Tech Stack

- Azure Data Factory
- Azure Databricks
- PySpark
- Delta Lake
- Azure Data Lake Gen2
- Parquet
- SQL
- Python

---

## ğŸ“‚ Repository Structure

```text
databricks_notebooks/
 â”œâ”€â”€ 1_Autoloader.ipynb
 â”œâ”€â”€ 2_silver.ipynb
 â”œâ”€â”€ 3_lookup.ipynb
 â”œâ”€â”€ 4_silver.ipynb
 â”œâ”€â”€ 5_LookUpNotebook.ipynb
 â”œâ”€â”€ 6_GetDayNumber.ipynb

factory/
dataset/
pipeline/
linkedService/
README.md
```
